{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07236cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:42.576495Z",
     "start_time": "2023-07-10T01:19:42.197736Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import copy\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def890b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:42.579871Z",
     "start_time": "2023-07-10T01:19:42.577370Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_window(data_dir: str,\n",
    "               trade_dates: np.ndarray,\n",
    "               time_window: int,\n",
    "               current_index: int = 0,\n",
    "               how:str = 'inner'\n",
    "              ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    从硬盘中整合eps的数据，读入内存。\n",
    "    输入参数为交易起始日，和时间窗口长度，\n",
    "    输出参数为一个pandas的df\n",
    "    \n",
    "    这个函数只在第一次调用的时候用到，读出的表格已经写入新的CSV文件，\n",
    "    之后的硬盘读取不再需要这个函数，而是直接使用read_csv()方法来完成。\n",
    "    \"\"\"\n",
    "    file_name = data_dir + 'eps_{}.csv'.format(trade_dates[current_index])\n",
    "    df = pd.read_csv(file_name, index_col=1).loc[:]['eps']\n",
    "\n",
    "    for i in range(1, time_window):\n",
    "\n",
    "        file_name = data_dir + 'eps_{}.csv'.format(trade_dates[current_index + i])\n",
    "        new_df = pd.read_csv(file_name, index_col=1).iloc[:]['eps']\n",
    "        df = pd.concat([df, new_df], join=how, axis=1)  # 取交集\n",
    "\n",
    "    df.columns = trade_dates[current_index:current_index + time_window]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c637f696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:42.583049Z",
     "start_time": "2023-07-10T01:19:42.581101Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_frame(data:pd.DataFrame,\n",
    "              time_window:int,\n",
    "             index_num:int,\n",
    "             direction:str)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    从内存中的数据框读取合适大小的数据用于计算\n",
    "    \"\"\"\n",
    "    \n",
    "    index_num += 1\n",
    "    if direction == 'forward':\n",
    "        df = data.iloc[:,index_num : index_num + time_window].dropna()\n",
    "    elif direction == 'backward':\n",
    "        df = data.iloc[:,index_num - time_window: index_num].dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbf26cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:42.584985Z",
     "start_time": "2023-07-10T01:19:42.583661Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def z_score(X: pd.DataFrame)->pd.DataFrame:\n",
    "    display(X)\n",
    "    return (X - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f2192a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:42.587296Z",
     "start_time": "2023-07-10T01:19:42.585607Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def find_trade_day(trade_dates:np.ndarray, day:int, direction:str = 'backward'):\n",
    "    \"\"\"\n",
    "    将输入的随便的数转化成列表中有的交易日\n",
    "    \"\"\"\n",
    "    if day in trade_dates: # 如果本来就在列表当中\n",
    "        nearest_trade_day = day\n",
    "    elif direction == 'backward':\n",
    "        nearest_trade_day = trade_dates[max((0, np.argmax(trade_dates - day >0) - 1))]\n",
    "    elif direction == 'forward':\n",
    "        nearest_trade_day = trade_dates[np.argmax(trade_dates - day >0)]\n",
    "        \n",
    "    return nearest_trade_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585f07cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:42.599873Z",
     "start_time": "2023-07-10T01:19:42.588064Z"
    },
    "code_folding": [
     0,
     185
    ]
   },
   "outputs": [],
   "source": [
    "def cal_strategy(period, step, start_day_index, skip_first_day,\n",
    "                 get_Xt, #关键的获得信号的函数\n",
    "                 is_display,\n",
    "                )-> tuple:\n",
    "    \"\"\"\n",
    "    将权重函数（信号）和未来的五日收益率相乘的到策略的未来收益率\n",
    "    ## 注意，这里的列名是指利用这一天及以前（含这一天）的数据对未来收益率做的预测。\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    daily_return = copy.deepcopy({'all':[],'top':[],'bottom':[]})\n",
    "    daily_signal = copy.deepcopy({'all':[],'top':[],'bottom':[]})\n",
    "    # 遍历我们要计算的每一天\n",
    "    for i in range(0,period,step): \n",
    "        \n",
    "        current_day_index =  start_day_index + i # 找到现在的交易日在交易日列表中的索引\n",
    "        current_day = trade_dates[current_day_index]\n",
    "\n",
    "        # 获取用于计算的数据框\n",
    "\n",
    "        df_return = get_frame(data=total_return,\n",
    "                             time_window=train_window, \n",
    "                             index_num = current_day_index,\n",
    "                             direction='backward') \n",
    "        \n",
    "        #  将数据框传到计算信号的函数当中。注意生成交易信号的时候就要判断是否多空\n",
    "\n",
    "        X = df_return.apply(get_Xt,axis=1).sort_values(ascending=False)\n",
    "        X.index = X.index.astype(int)\n",
    "        \n",
    "#         取与股票池的交集\n",
    "        if is_intersect is True:\n",
    "            current_target_stocks = target_stock.loc[:][current_day].dropna()\n",
    "            current_target_stocks = current_target_stocks.astype(int)\n",
    "            \n",
    "            intersec_stock = pd.Series(list(set(X.index).intersection(set(current_target_stocks.values))))\n",
    "            X = X.loc[intersec_stock][:]\n",
    "            df_return=df_return.loc[intersec_stock][:]\n",
    "        \n",
    "        X = X.astype(float)\n",
    "        X = (X - np.mean(X)) / np.std(X)  # 做 z-score\n",
    "        X[X > 3] = 3\n",
    "        X[X < -3]  = -3\n",
    "\n",
    "\n",
    "        top =  X[X > 0].index\n",
    "        bottom = X[X < 0].index\n",
    "\n",
    "        df_X = pd.DataFrame(np.zeros((len(df_return.index),3)), # 先生成全 0 矩阵，方便后面的加法\n",
    "                         columns=['all','top','bottom'], index=df_return.index)\n",
    "\n",
    "        df_X.loc[top, 'top'] = X[top] / X[top].sum()\n",
    "        df_X.loc[bottom ,'bottom'] = - X[bottom] / X[bottom].sum()\n",
    "        df_X['all'] = df_X['top'] + df_X['bottom']\n",
    "        df_X.replace(0, np.nan, inplace=True)\n",
    "        X = df_X\n",
    "\n",
    "        if skip_first_day is True: # 如果要跳过第一天的话\n",
    "            current_day_index += 1\n",
    "        \n",
    "        # 获取用于计算未来收益率的数据框\n",
    "        test_return = get_frame(data=total_return,\n",
    "                               time_window=test_window,\n",
    "                               index_num=current_day_index,\n",
    "                               direction='forward')\n",
    "        \n",
    "        # 计算今日的收益率\n",
    "        for column in X.columns:\n",
    "            daily_signal[column].append(X[column])\n",
    "            daily_return[column].append((test_return.sum(axis=1) * X[column]).dropna())\n",
    "         \n",
    "        \n",
    "\n",
    "    \n",
    "    # 将列表中的Series统一拼接\n",
    "    strategy_return = copy.deepcopy({})\n",
    "    strategy_signal = copy.deepcopy({})\n",
    "    for key in daily_return.keys():\n",
    "        strategy_return[key] = pd.concat(daily_return[key], axis=1, join='outer')\n",
    "        strategy_signal[key] = pd.concat(daily_signal[key], axis=1, join='outer')\n",
    "        \n",
    "        strategy_return[key].columns= trade_dates[range(start_day_index,start_day_index + period, step)]\n",
    "        strategy_signal[key].columns= trade_dates[range(start_day_index,start_day_index + period, step)]\n",
    "        \n",
    "    strategy_return['all'] = (strategy_return['top'].replace(np.nan,0)-strategy_return['bottom'].replace(np.nan,0)).replace(0,np.nan)\n",
    "    strategy_return['bottom'] = -strategy_return['bottom']\n",
    "#     if note is not None:\n",
    "#         for key in daily_return.keys():\n",
    "#             strategy_return[key].to_csv(f'./data/strategy_return_{key}/' + note +'.csv',encoding='gbk',index=True)\n",
    "#             strategy_signal[key].to_csv(f'./data/strategy_signal_{key}/' + note +'.csv',encoding='gbk',index=True)\n",
    "#             header = not os.path.isfile('modified_return.csv')\n",
    "#             daily_return = pd.DataFrame(strategy_return[key].sum(),columns=[note,]).T\n",
    "#             daily_return.to_csv('modified_return.csv', header=header,index=True,encoding='gbk',mode='a')\n",
    "\n",
    "    return strategy_return, strategy_signal\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "def show_strategy(strategy_return:dict,\n",
    "                  strategy_signal:dict,\n",
    "                  bench_mark:pd.Series,\n",
    "                  long_short: str,\n",
    "                  step: int = 5, \n",
    "                  note: str = '', \n",
    "                  is_display: bool = False,\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    展示策略收益的函数，具有普遍适用性。\n",
    "    这个函数需要绘制一些图片、计算一些数据，并存储到CSV文件当中\n",
    "    具体而言，需要计算的比例有：\n",
    "    （全策略、纯空头、纯多头的）胜率、回测收益、\n",
    "    \"\"\"\n",
    "    daily_return = copy.deepcopy({})\n",
    "    backtest_params = copy.deepcopy({})\n",
    "    cumulative_return = copy.deepcopy({})\n",
    "    drawdowns = copy.deepcopy({})\n",
    "    tov_seq = copy.deepcopy({})\n",
    "    \n",
    "    for key in strategy_return.keys(): # 遍历每种组合的情况\n",
    "        \n",
    "        # 计算组合的日收益率、累计收益率序列\n",
    "        daily_return[key] = strategy_return[key].sum()\n",
    "        cumulative_return[key] = daily_return[key].cumsum()\n",
    "\n",
    "        # 计算日均收益率、日均波动率、IR、下行偏差DD\n",
    "        backtest_params[key + '_' + '日均收益率R'] = daily_return[key].mean() / step\n",
    "        backtest_params[key + '_' + '日均波动率Vol'] = daily_return[key].std() / np.sqrt(step)\n",
    "        \n",
    "        backtest_params[key + '_' + '年化收益率ER'] = backtest_params[key + '_' + '日均收益率R'] * 252\n",
    "        backtest_params[key + '_' + '年化波动率VOL'] = backtest_params[key + '_' + '日均波动率Vol'] * np.sqrt(252)\n",
    "        \n",
    "        backtest_params[key + '_' + '信息比率IR'] = backtest_params[key + '_' + '日均收益率R'] / backtest_params[key + '_' + '日均波动率Vol']\n",
    "        backtest_params[key + '_' + '夏普比率SR'] = backtest_params[key + '_' + '信息比率IR'] * np.sqrt(252)\n",
    "\n",
    "        backtest_params[key + '_' + '下行偏差DD'] = daily_return[key][daily_return[key] < 0].std()\n",
    "        \n",
    "        # 计算胜率：取每日胜率的平均值\n",
    "        ve_seq = np.count_nonzero(strategy_return[key] > 0, axis = 0) / strategy_return[key].notna().sum(axis=0)\n",
    "        backtest_params[key + '_' + '胜率VE'] = ve_seq.mean()\n",
    "    \n",
    "        # 计算盈亏比：取每日盈亏比的平均值\n",
    "        gain = strategy_return[key][strategy_return[key] > 0].mean(axis=0)\n",
    "        loss = strategy_return[key][strategy_return[key] < 0].mean(axis=0)\n",
    "        backtest_params[key + '_' + '盈亏比PnL'] = (gain / abs(loss)).mean()\n",
    "        \n",
    "        # 计算最大回撤\n",
    "        max_so_far = cumulative_return[key].values[0]\n",
    "        drawdowns[key] = []\n",
    "        for trade_day in cumulative_return[key].index:\n",
    "            \n",
    "            if cumulative_return[key][trade_day] > max_so_far:\n",
    "                drawdown = 0\n",
    "                drawdowns[key].append(drawdown)\n",
    "                max_so_far = cumulative_return[key][trade_day]\n",
    "            else:\n",
    "                drawdown =  max_so_far - cumulative_return[key][trade_day]\n",
    "                drawdowns[key].append(drawdown)\n",
    "            \n",
    "        \n",
    "        backtest_params[key + '_' + '最大回撤MDD'] = max(drawdowns[key])\n",
    "        \n",
    "        # 计算Calmar比率、Sortino比率\n",
    "        backtest_params[key + '_' + '卡玛比率Calmar'] = backtest_params[key + '_' + '年化收益率ER'] / backtest_params[key + '_' + '最大回撤MDD']\n",
    "        backtest_params[key + '_' + '索提诺比率Sortino'] = backtest_params[key + '_' + '年化收益率ER'] / backtest_params[key + '_' + '下行偏差DD']\n",
    "        \n",
    "        # 计算换手率\n",
    "#         daily_holding = strategy_signal[key] / strategy_signal[key].notna().sum(axis=0)# 先将交易信号转化为持仓数\n",
    "        daily_holding = strategy_signal[key]\n",
    "        prior = daily_holding.iloc[:, :daily_holding.shape[1] - 1].fillna(0)\n",
    "        rear = daily_holding.iloc[:,1:daily_holding.shape[1]].fillna(0)\n",
    "        \n",
    "        prior.columns, rear.columns = range(daily_holding.shape[1] - 1),range(daily_holding.shape[1] - 1) # 为了df可以准确做减法，需要修改对齐列名\n",
    "        \n",
    "        tov_seq[key] = (rear - prior).abs().sum(axis=0) / 2\n",
    "        tov_seq[key] = pd.concat([pd.Series(.5), tov_seq[key]])\n",
    "        backtest_params[key + '_' + '换手率Tov'] = tov_seq[key].mean()\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(backtest_params,orient='index')\n",
    "\n",
    "    \n",
    "    # 修改显示方式\n",
    "    names = np.array(df.index).reshape((-1,3),order='F').reshape((1,-1),order='C').tolist()[0]\n",
    "    df = df.loc[names,:]\n",
    "    '''    \n",
    "        # 绘制回测收益率曲线、当日回撤柱状图、换手率柱状图\n",
    "        x = pd.to_datetime(daily_return[long_short].index,format='%Y%m%d')\n",
    "        time_str = time.strftime('%Y%m%d_%H%M%S',time.localtime())\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(16,5)) \n",
    "\n",
    "        plt.plot(x, cumulative_return['all'] * 100, color='r')\n",
    "        plt.plot(x, cumulative_return['top'] * 100, color='g')\n",
    "        plt.plot(x, cumulative_return['bottom'] * 100, color='b')\n",
    "\n",
    "        plt.plot(x, bench_mark * 100, color='k')\n",
    "\n",
    "        plt.legend(['Strategy_all','Strategy_top','Strategy_bottom','Benchmark'])\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Cumulative Return %')\n",
    "        plt.title('CUMULATIVE RETURN', )\n",
    "        if note is not None: \n",
    "            note = time_str + '_' + note\n",
    "            plt.savefig('./XSMOM_image/' + note + '.png') # 保存图片\n",
    "\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(16,6))\n",
    "        plt.subplot(211)\n",
    "        plt.bar(x, - np.array(drawdowns[long_short]) * 100,)\n",
    "        plt.ylabel('Max Drawdown %')\n",
    "        plt.title('DRAWDOWN')\n",
    "\n",
    "        plt.subplot(212)\n",
    "        tov_show = tov_seq[long_short]\n",
    "        tov_show[0] = 0\n",
    "        plt.bar(x,tov_show * 100)\n",
    "\n",
    "        plt.ylabel('Turnover Rate %')\n",
    "        plt.xlabel('Date')\n",
    "        plt.title('TURNOVER RATE')\n",
    "        plt.show()\n",
    "    '''\n",
    "    \n",
    "    # 写入CSV文件。\n",
    "    if note is None: \n",
    "        return\n",
    "    df_log = df.T\n",
    "    \n",
    "    df_log.index = [note,]\n",
    "    header = not os.path.isfile('XSMOM_modify.csv') # 如果文件存在，则不要写入表头。如果文件不存在则写入表头\n",
    "    df_log.to_csv('XSMOM_modify.csv', mode='a', index=True, header=header, encoding='gbk')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c555a23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:42.603957Z",
     "start_time": "2023-07-10T01:19:42.600697Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def main(get_Xt, # 这是需要的输出信号的名称\n",
    "         start_day:int = 20210101,\n",
    "         end_day:int = 20221231,\n",
    "         skip_first_day:bool = True,\n",
    "         step:int = 5,\n",
    "         long_short: str = 'all', # 限制字段，可选'none','short','long','all',默认为'all'，这个字段仅用作画图。而所有的数据都会计算\n",
    "         note: str = '', # 记录调参细节等内容的字段，将写入最后的日志文件\n",
    "         read: bool = False, # 写入csv\n",
    "         is_display: bool = False,\n",
    "         \n",
    "        ):\n",
    "    \"\"\"\n",
    "    回测的主函数。\n",
    "    需要实现的功能有：\n",
    "    1. 初始化\n",
    "    2. 运行回测收益并存储数据\n",
    "    3. 计算回测结果、相应收益指标等元素，并存储到csv文件中\n",
    "    \"\"\"\n",
    "    \n",
    "    # 初始化部分\n",
    "    \n",
    "    \n",
    "    start_day = find_trade_day(trade_dates, start_day, 'forward')\n",
    "    start_day_index = int(np.where(trade_dates == start_day)[0])\n",
    "    end_day = find_trade_day(trade_dates, end_day, 'backward')\n",
    "    end_day_index = int(np.where(trade_dates == end_day)[0])\n",
    "    period = end_day_index - start_day_index\n",
    "    \n",
    "    bench_mark = zz500.iloc[start_day_index:end_day_index].cumsum().iloc[range(0,period,step)]\n",
    "    \n",
    "    if read is True and note is not None:\n",
    "        \n",
    "        strategy_return = copy.deepcopy({})\n",
    "        strategy_signal = copy.deepcopy({})\n",
    "        for key in ['all', 'top', 'short']:\n",
    "            \n",
    "            strategy_return[key] = pd.read_csv(f'./data/strategy_return_{key}/' + note +'.csv',encoding='gbk',index_col=0)\n",
    "            strategy_signal[key] = pd.read_csv(f'./data/strategy_signal_{key}/' + note +'.csv',encoding='gbk',index_col=0)\n",
    "            \n",
    "    else:\n",
    "        strategy_return, strategy_signal = cal_strategy(period, step, start_day_index, skip_first_day,get_Xt, is_display) ###\n",
    "    \n",
    "    show_strategy(strategy_return, strategy_signal, bench_mark, long_short, step, note,is_display)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b91b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:43.877271Z",
     "start_time": "2023-07-10T01:19:42.604700Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZZ500</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20170103</th>\n",
       "      <td>0.009122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170104</th>\n",
       "      <td>0.011693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170105</th>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170106</th>\n",
       "      <td>-0.004323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170109</th>\n",
       "      <td>0.006874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230424</th>\n",
       "      <td>-0.006682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230425</th>\n",
       "      <td>-0.014597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230426</th>\n",
       "      <td>0.003923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230427</th>\n",
       "      <td>0.002569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20230428</th>\n",
       "      <td>0.013529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1537 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ZZ500\n",
       "dt                \n",
       "20170103  0.009122\n",
       "20170104  0.011693\n",
       "20170105  0.000722\n",
       "20170106 -0.004323\n",
       "20170109  0.006874\n",
       "...            ...\n",
       "20230424 -0.006682\n",
       "20230425 -0.014597\n",
       "20230426  0.003923\n",
       "20230427  0.002569\n",
       "20230428  0.013529\n",
       "\n",
       "[1537 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20170103</th>\n",
       "      <th>20170104</th>\n",
       "      <th>20170105</th>\n",
       "      <th>20170106</th>\n",
       "      <th>20170109</th>\n",
       "      <th>20170110</th>\n",
       "      <th>20170111</th>\n",
       "      <th>20170112</th>\n",
       "      <th>20170113</th>\n",
       "      <th>20170116</th>\n",
       "      <th>...</th>\n",
       "      <th>20230420</th>\n",
       "      <th>20230421</th>\n",
       "      <th>20230424</th>\n",
       "      <th>20230425</th>\n",
       "      <th>20230426</th>\n",
       "      <th>20230427</th>\n",
       "      <th>20230428</th>\n",
       "      <th>20230504</th>\n",
       "      <th>20230505</th>\n",
       "      <th>20230508</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CodeInt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-0.003937</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>-0.004754</td>\n",
       "      <td>-0.009661</td>\n",
       "      <td>-0.009346</td>\n",
       "      <td>-0.002768</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>-0.010721</td>\n",
       "      <td>-0.039373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011273</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>-0.014180</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>-0.016329</td>\n",
       "      <td>-0.016141</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.023087</td>\n",
       "      <td>0.035650</td>\n",
       "      <td>0.037762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.000711</td>\n",
       "      <td>-0.005624</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>-0.007031</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.069572</td>\n",
       "      <td>0.034962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220414</td>\n",
       "      <td>0.217020</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.181784</td>\n",
       "      <td>0.178815</td>\n",
       "      <td>0.196727</td>\n",
       "      <td>0.181249</td>\n",
       "      <td>0.214145</td>\n",
       "      <td>0.199537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>-0.012706</td>\n",
       "      <td>-0.021648</td>\n",
       "      <td>-0.026045</td>\n",
       "      <td>-0.030087</td>\n",
       "      <td>-0.056350</td>\n",
       "      <td>-0.040720</td>\n",
       "      <td>-0.045468</td>\n",
       "      <td>-0.047901</td>\n",
       "      <td>-0.052015</td>\n",
       "      <td>-0.062331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633625</td>\n",
       "      <td>0.618704</td>\n",
       "      <td>0.650342</td>\n",
       "      <td>0.635326</td>\n",
       "      <td>0.616098</td>\n",
       "      <td>0.644642</td>\n",
       "      <td>0.630193</td>\n",
       "      <td>0.676022</td>\n",
       "      <td>0.703101</td>\n",
       "      <td>0.671319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.006572</td>\n",
       "      <td>0.020866</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>0.031316</td>\n",
       "      <td>0.030033</td>\n",
       "      <td>0.019092</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460491</td>\n",
       "      <td>-0.459247</td>\n",
       "      <td>-0.480376</td>\n",
       "      <td>-0.463113</td>\n",
       "      <td>-0.471025</td>\n",
       "      <td>-0.489864</td>\n",
       "      <td>-0.483946</td>\n",
       "      <td>-0.541763</td>\n",
       "      <td>-0.553666</td>\n",
       "      <td>-0.595196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.033770</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>-0.021703</td>\n",
       "      <td>-0.055263</td>\n",
       "      <td>-0.067230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249777</td>\n",
       "      <td>-0.257375</td>\n",
       "      <td>-0.267241</td>\n",
       "      <td>-0.274677</td>\n",
       "      <td>-0.279480</td>\n",
       "      <td>-0.283479</td>\n",
       "      <td>-0.282154</td>\n",
       "      <td>-0.292470</td>\n",
       "      <td>-0.274997</td>\n",
       "      <td>-0.291191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301387.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.091205</td>\n",
       "      <td>-0.110193</td>\n",
       "      <td>-0.157357</td>\n",
       "      <td>-0.166558</td>\n",
       "      <td>-0.168862</td>\n",
       "      <td>-0.161303</td>\n",
       "      <td>-0.156582</td>\n",
       "      <td>-0.122120</td>\n",
       "      <td>-0.145462</td>\n",
       "      <td>-0.140088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603137.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154557</td>\n",
       "      <td>-0.230836</td>\n",
       "      <td>-0.222200</td>\n",
       "      <td>-0.247647</td>\n",
       "      <td>-0.268766</td>\n",
       "      <td>-0.261459</td>\n",
       "      <td>-0.239417</td>\n",
       "      <td>-0.229618</td>\n",
       "      <td>-0.232630</td>\n",
       "      <td>-0.218486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301307.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016043</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.061570</td>\n",
       "      <td>0.017362</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>-0.054162</td>\n",
       "      <td>-0.043375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301360.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037177</td>\n",
       "      <td>0.023285</td>\n",
       "      <td>0.074572</td>\n",
       "      <td>0.035899</td>\n",
       "      <td>-0.052570</td>\n",
       "      <td>0.047279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301293.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.040803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4562 rows × 1540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          20170103  20170104  20170105  20170106  20170109  20170110  \\\n",
       "CodeInt                                                                \n",
       "1.0      -0.003937 -0.005309 -0.002760 -0.004754 -0.009661 -0.009346   \n",
       "2.0       0.000711 -0.005624 -0.000174  0.006677  0.005278 -0.004972   \n",
       "4.0      -0.012706 -0.021648 -0.026045 -0.030087 -0.056350 -0.040720   \n",
       "5.0       0.006572  0.020866  0.019645  0.028747  0.031316  0.030033   \n",
       "6.0       0.010616  0.010543  0.010402  0.033770  0.017014  0.000989   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "301387.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "603137.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "301307.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "301360.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "301293.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          20170111  20170112  20170113  20170116  ...  20230420  20230421  \\\n",
       "CodeInt                                           ...                       \n",
       "1.0      -0.002768  0.003897 -0.010721 -0.039373  ...  0.011273  0.007321   \n",
       "2.0      -0.007031  0.001514  0.069572  0.034962  ...  0.220414  0.217020   \n",
       "4.0      -0.045468 -0.047901 -0.052015 -0.062331  ...  0.633625  0.618704   \n",
       "5.0       0.019092  0.015007  0.012857  0.023810  ... -0.460491 -0.459247   \n",
       "6.0       0.008082 -0.021703 -0.055263 -0.067230  ... -0.249777 -0.257375   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "301387.0       NaN       NaN       NaN       NaN  ... -0.091205 -0.110193   \n",
       "603137.0       NaN       NaN       NaN       NaN  ... -0.154557 -0.230836   \n",
       "301307.0       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "301360.0       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "301293.0       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "\n",
       "          20230424  20230425  20230426  20230427  20230428  20230504  \\\n",
       "CodeInt                                                                \n",
       "1.0      -0.014180  0.003221 -0.016329 -0.016141  0.010179  0.023087   \n",
       "2.0       0.203900  0.204323  0.181784  0.178815  0.196727  0.181249   \n",
       "4.0       0.650342  0.635326  0.616098  0.644642  0.630193  0.676022   \n",
       "5.0      -0.480376 -0.463113 -0.471025 -0.489864 -0.483946 -0.541763   \n",
       "6.0      -0.267241 -0.274677 -0.279480 -0.283479 -0.282154 -0.292470   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "301387.0 -0.157357 -0.166558 -0.168862 -0.161303 -0.156582 -0.122120   \n",
       "603137.0 -0.222200 -0.247647 -0.268766 -0.261459 -0.239417 -0.229618   \n",
       "301307.0       NaN -0.016043  0.000387  0.061570  0.017362  0.003487   \n",
       "301360.0       NaN       NaN  0.037177  0.023285  0.074572  0.035899   \n",
       "301293.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          20230505  20230508  \n",
       "CodeInt                       \n",
       "1.0       0.035650  0.037762  \n",
       "2.0       0.214145  0.199537  \n",
       "4.0       0.703101  0.671319  \n",
       "5.0      -0.553666 -0.595196  \n",
       "6.0      -0.274997 -0.291191  \n",
       "...            ...       ...  \n",
       "301387.0 -0.145462 -0.140088  \n",
       "603137.0 -0.232630 -0.218486  \n",
       "301307.0 -0.054162 -0.043375  \n",
       "301360.0 -0.052570  0.047279  \n",
       "301293.0       NaN -0.040803  \n",
       "\n",
       "[4562 rows x 1540 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20170103</th>\n",
       "      <th>20170104</th>\n",
       "      <th>20170105</th>\n",
       "      <th>20170106</th>\n",
       "      <th>20170109</th>\n",
       "      <th>20170110</th>\n",
       "      <th>20170111</th>\n",
       "      <th>20170112</th>\n",
       "      <th>20170113</th>\n",
       "      <th>20170116</th>\n",
       "      <th>...</th>\n",
       "      <th>20230420</th>\n",
       "      <th>20230421</th>\n",
       "      <th>20230424</th>\n",
       "      <th>20230425</th>\n",
       "      <th>20230426</th>\n",
       "      <th>20230427</th>\n",
       "      <th>20230428</th>\n",
       "      <th>20230504</th>\n",
       "      <th>20230505</th>\n",
       "      <th>20230508</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CodeInt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-0.003937</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>-0.001994</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>-0.014618</td>\n",
       "      <td>-0.028652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>-0.003953</td>\n",
       "      <td>-0.021501</td>\n",
       "      <td>0.017401</td>\n",
       "      <td>-0.019549</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.026320</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.012563</td>\n",
       "      <td>0.002112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.000711</td>\n",
       "      <td>-0.006336</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>-0.034610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>-0.003394</td>\n",
       "      <td>-0.013119</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-0.022540</td>\n",
       "      <td>-0.002969</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>-0.015478</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>-0.014607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>-0.012706</td>\n",
       "      <td>-0.008942</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>-0.026262</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>-0.004748</td>\n",
       "      <td>-0.002432</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>-0.014921</td>\n",
       "      <td>0.031638</td>\n",
       "      <td>-0.015016</td>\n",
       "      <td>-0.019228</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>-0.014449</td>\n",
       "      <td>0.045829</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>-0.031783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.006572</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>-0.001220</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>-0.010941</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003068</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>-0.021130</td>\n",
       "      <td>0.017263</td>\n",
       "      <td>-0.007911</td>\n",
       "      <td>-0.018840</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>-0.057817</td>\n",
       "      <td>-0.011903</td>\n",
       "      <td>-0.041529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.010616</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.023368</td>\n",
       "      <td>-0.016755</td>\n",
       "      <td>-0.016026</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>-0.029784</td>\n",
       "      <td>-0.033560</td>\n",
       "      <td>-0.011968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007278</td>\n",
       "      <td>-0.007598</td>\n",
       "      <td>-0.009866</td>\n",
       "      <td>-0.007437</td>\n",
       "      <td>-0.004803</td>\n",
       "      <td>-0.003999</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.010316</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>-0.016194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301387.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014547</td>\n",
       "      <td>-0.018988</td>\n",
       "      <td>-0.047164</td>\n",
       "      <td>-0.009201</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.034462</td>\n",
       "      <td>-0.023341</td>\n",
       "      <td>0.005374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603137.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154557</td>\n",
       "      <td>-0.076278</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>-0.025447</td>\n",
       "      <td>-0.021118</td>\n",
       "      <td>0.007307</td>\n",
       "      <td>0.022041</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>-0.003012</td>\n",
       "      <td>0.014144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301307.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016043</td>\n",
       "      <td>0.016430</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>-0.044208</td>\n",
       "      <td>-0.013875</td>\n",
       "      <td>-0.057650</td>\n",
       "      <td>0.010787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301360.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037177</td>\n",
       "      <td>-0.013891</td>\n",
       "      <td>0.051287</td>\n",
       "      <td>-0.038673</td>\n",
       "      <td>-0.088469</td>\n",
       "      <td>0.099848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301293.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.040803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4562 rows × 1540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          20170103  20170104  20170105  20170106  20170109  20170110  \\\n",
       "CodeInt                                                                \n",
       "1.0      -0.003937 -0.001372  0.002549 -0.001994 -0.004906  0.000314   \n",
       "2.0       0.000711 -0.006336  0.005450  0.006851 -0.001399 -0.010250   \n",
       "4.0      -0.012706 -0.008942 -0.004397 -0.004043 -0.026262  0.015629   \n",
       "5.0       0.006572  0.014294 -0.001220  0.009102  0.002568 -0.001283   \n",
       "6.0       0.010616 -0.000073 -0.000141  0.023368 -0.016755 -0.016026   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "301387.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "603137.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "301307.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "301360.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "301293.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          20170111  20170112  20170113  20170116  ...  20230420  20230421  \\\n",
       "CodeInt                                           ...                       \n",
       "1.0       0.006578  0.006665 -0.014618 -0.028652  ...  0.003602 -0.003953   \n",
       "2.0      -0.002059  0.008545  0.068058 -0.034610  ...  0.009222 -0.003394   \n",
       "4.0      -0.004748 -0.002432 -0.004115 -0.010316  ...  0.008010 -0.014921   \n",
       "5.0      -0.010941 -0.004085 -0.002150  0.010953  ... -0.003068  0.001244   \n",
       "6.0       0.007093 -0.029784 -0.033560 -0.011968  ... -0.007278 -0.007598   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "301387.0       NaN       NaN       NaN       NaN  ... -0.014547 -0.018988   \n",
       "603137.0       NaN       NaN       NaN       NaN  ... -0.154557 -0.076278   \n",
       "301307.0       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "301360.0       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "301293.0       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "\n",
       "          20230424  20230425  20230426  20230427  20230428  20230504  \\\n",
       "CodeInt                                                                \n",
       "1.0      -0.021501  0.017401 -0.019549  0.000188  0.026320  0.012908   \n",
       "2.0      -0.013119  0.000423 -0.022540 -0.002969  0.017913 -0.015478   \n",
       "4.0       0.031638 -0.015016 -0.019228  0.028544 -0.014449  0.045829   \n",
       "5.0      -0.021130  0.017263 -0.007911 -0.018840  0.005918 -0.057817   \n",
       "6.0      -0.009866 -0.007437 -0.004803 -0.003999  0.001325 -0.010316   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "301387.0 -0.047164 -0.009201 -0.002304  0.007560  0.004721  0.034462   \n",
       "603137.0  0.008636 -0.025447 -0.021118  0.007307  0.022041  0.009799   \n",
       "301307.0       NaN -0.016043  0.016430  0.061183 -0.044208 -0.013875   \n",
       "301360.0       NaN       NaN  0.037177 -0.013891  0.051287 -0.038673   \n",
       "301293.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "          20230505  20230508  \n",
       "CodeInt                       \n",
       "1.0       0.012563  0.002112  \n",
       "2.0       0.032895 -0.014607  \n",
       "4.0       0.027079 -0.031783  \n",
       "5.0      -0.011903 -0.041529  \n",
       "6.0       0.017473 -0.016194  \n",
       "...            ...       ...  \n",
       "301387.0 -0.023341  0.005374  \n",
       "603137.0 -0.003012  0.014144  \n",
       "301307.0 -0.057650  0.010787  \n",
       "301360.0 -0.088469  0.099848  \n",
       "301293.0       NaN -0.040803  \n",
       "\n",
       "[4562 rows x 1540 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20170103</th>\n",
       "      <th>20170104</th>\n",
       "      <th>20170105</th>\n",
       "      <th>20170106</th>\n",
       "      <th>20170109</th>\n",
       "      <th>20170110</th>\n",
       "      <th>20170111</th>\n",
       "      <th>20170112</th>\n",
       "      <th>20170113</th>\n",
       "      <th>20170116</th>\n",
       "      <th>...</th>\n",
       "      <th>20230417</th>\n",
       "      <th>20230418</th>\n",
       "      <th>20230419</th>\n",
       "      <th>20230420</th>\n",
       "      <th>20230421</th>\n",
       "      <th>20230424</th>\n",
       "      <th>20230425</th>\n",
       "      <th>20230426</th>\n",
       "      <th>20230427</th>\n",
       "      <th>20230428</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2887 rows × 1537 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      20170103  20170104  20170105  20170106  20170109  20170110  20170111  \\\n",
       "0          2.0       2.0       2.0       2.0       2.0       2.0       2.0   \n",
       "1          4.0       4.0       4.0       4.0       4.0       4.0       4.0   \n",
       "2         34.0      34.0      34.0      34.0      34.0      34.0      34.0   \n",
       "3         59.0      59.0      59.0      59.0      59.0      59.0      59.0   \n",
       "4         63.0      63.0       NaN       NaN       NaN       NaN       NaN   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2882       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2883       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2884       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2885       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2886       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "      20170112  20170113  20170116  ...  20230417  20230418  20230419  \\\n",
       "0          4.0       4.0       NaN  ...       NaN       NaN       NaN   \n",
       "1          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2          NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "3          NaN       NaN       NaN  ...      88.0      88.0      88.0   \n",
       "4         63.0      63.0       NaN  ...       NaN       NaN       NaN   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2882       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2883       NaN       NaN       NaN  ...      28.0      28.0      28.0   \n",
       "2884       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2885       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2886       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "      20230420  20230421  20230424  20230425  20230426  20230427  20230428  \n",
       "0          NaN       NaN       2.0       2.0       2.0       2.0       2.0  \n",
       "1          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "3         88.0      88.0      88.0      88.0      88.0      88.0       NaN  \n",
       "4          NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2882       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2883      28.0      28.0      28.0       NaN       NaN      28.0      28.0  \n",
       "2884       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2885       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2886       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[2887 rows x 1537 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 数据读取准备工作\n",
    "data_dir = '../华安证券深度神经网络改进时间序列动量策略/baz_TSMOM/'\n",
    "\n",
    "trade_dates = np.load(data_dir + 'tradedates.npy')\n",
    "trade_dates = trade_dates[(trade_dates>=20170103) & (trade_dates <= 20230500)]\n",
    "train_window =  5\n",
    "test_window = 5\n",
    "\n",
    "\n",
    "# total_day = trade_dates.shape[0] # 文件中拥有的全部天数\n",
    "# total_return = get_window(data_dir=data_dir,\n",
    "#                           trade_dates=trade_dates,\n",
    "#                           time_window=total_day, # 一次全部读出\n",
    "#                           current_index=0,\n",
    "#                           how='outer')\n",
    "# display(total_return)\n",
    "# print(f'the size of train_return is {getsizeof(total_return) / (1024 * 1024):4.2f} MB.')\n",
    "# total_price = total_return.cumsum(axis=1)\n",
    "# display(total_price)\n",
    "# total_return.to_csv('total_return.csv')\n",
    "# total_price.to_csv('total_price.csv')\n",
    "\n",
    "total_price=pd.read_csv(data_dir + 'total_price.csv',index_col=0)\n",
    "total_return = pd.read_csv(data_dir + 'total_return.csv' ,index_col=0)\n",
    "zz500 = pd.read_csv(data_dir + 'ZZ500.csv',index_col=0)\n",
    "target_stock = pd.read_csv(data_dir + 'target_stock.csv',index_col=0)\n",
    "\n",
    "total_price.columns = pd.to_numeric(total_price.columns) # 方便后文的整数索引\n",
    "total_return.columns = pd.to_numeric(total_return.columns)\n",
    "target_stock.columns = pd.to_numeric(target_stock.columns)\n",
    "zz500 = zz500.loc[trade_dates]\n",
    "\n",
    "display(zz500)\n",
    "display(total_price)\n",
    "display(total_return)\n",
    "display(target_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495b386d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:43.884763Z",
     "start_time": "2023-07-10T01:19:43.879500Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 1, 2, 1, 5, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longest_above_mean, longest_above_median\n",
    "import itertools\n",
    "\n",
    "def _get_length_sequences_where(x):\n",
    "    \"\"\"\n",
    "    This method calculates the length of all sub-sequences where the array x is either True or 1.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    :param x: An iterable containing only 1, True, 0 and False values\n",
    "    :return: A list with the length of all sub-sequences where the array is either True or False. If no ones or Trues\n",
    "    contained, the list [0] is returned.\n",
    "    \"\"\"\n",
    "    if len(x) == 0:\n",
    "        return [0]\n",
    "    else:\n",
    "        res = [len(list(group)) for value, group in itertools.groupby(x) if value == 1]\n",
    "        return res if len(res) > 0 else [0]\n",
    "\n",
    "def longest_above_mean(x):\n",
    "    \"\"\"\n",
    "    Returns the length of the longest consecutive subsequence in x that is bigger than the mean of x\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.max(_get_length_sequences_where(x > np.mean(x))) if x.size > 0 else 0\n",
    "\n",
    "def longest_above_median(x):\n",
    "    \n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.max(_get_length_sequences_where(x > np.median(x))) if x.size > 0 else 0\n",
    "\n",
    "a = np.random.randn(24)\n",
    "a = (np.sign(np.sign(a) + 1))\n",
    "display(a)\n",
    "_get_length_sequences_where(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0292f1e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:43.887210Z",
     "start_time": "2023-07-10T01:19:43.885397Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def large_std_dev(x):\n",
    "    \"\"\"\n",
    "    Does time series have *large* standard deviation?\n",
    "\n",
    "    Boolean variable denoting if the standard dev of x is higher than 'r' times the range = difference between max and\n",
    "    min of x. Hence it checks if\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        std(x) > r * (max(X)-min(X))\n",
    "\n",
    "    According to a rule of the thumb, the standard deviation should be a forth of the range of the values.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param r: the percentage of the range to compare with\n",
    "    :type r: float\n",
    "    :return: the value of this feature\n",
    "    :return type: bool\n",
    "    \"\"\"\n",
    "    \n",
    "    # 改进版本：不再判断是否r 倍于极差，而是输出标准差和极差的比值\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    return np.std(x) / (np.max(x) - np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f199636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:43.889622Z",
     "start_time": "2023-07-10T01:19:43.887937Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _roll(a, shift):\n",
    "    \"\"\"\n",
    "    Roll 1D array elements. Improves the performance of numpy.roll() by reducing the overhead introduced from the\n",
    "    flexibility of the numpy.roll() method such as the support for rolling over multiple dimensions.\n",
    "\n",
    "    Elements that roll beyond the last position are re-introduced at the beginning. Similarly, elements that roll\n",
    "    back beyond the first position are re-introduced at the end (with negative shift).\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Benchmark\n",
    "    ---------\n",
    "    :param a: the input array\n",
    "    :type a: array_like\n",
    "    :param shift: the number of places by which elements are shifted\n",
    "    :type shift: int\n",
    "\n",
    "    :return: shifted array with the same shape as a\n",
    "    :return type: ndarray\n",
    "    \"\"\"\n",
    "    # 这个函数相当于把一位数组的前lag项放到了后面，\n",
    "    if not isinstance(a, np.ndarray):\n",
    "        a = np.asarray(a)\n",
    "    idx = shift % len(a) # shift 除以 len(a)的余数\n",
    "    return np.concatenate([a[-idx:], a[:-idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d29b53ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:43.893149Z",
     "start_time": "2023-07-10T01:19:43.890340Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_peaks(x, n = 5):\n",
    "    \"\"\"\n",
    "    Calculates the number of peaks of at least support n in the time series x. A peak of support n is defined as a\n",
    "    subsequence of x where a value occurs, which is bigger than its n neighbours to the left and to the right.\n",
    "\n",
    "    Hence in the sequence\n",
    "\n",
    "    4 is a peak of support 1 and 2 because in the subsequences\n",
    "\n",
    "    4 is still the highest value. Here, 4 is not a peak of support 3 because 13 is the 3th neighbour to the right of 4\n",
    "    and its bigger than 4.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param n: the support of the peak\n",
    "    :type n: int\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    x_reduced = x[n:-n]\n",
    "\n",
    "    res = None\n",
    "    for i in range(1, n + 1):\n",
    "        result_first = x_reduced > _roll(x, i)[n:-n]\n",
    "        \n",
    "        if res is None:\n",
    "            res = result_first\n",
    "        else:\n",
    "            res &= result_first\n",
    "\n",
    "        res &= x_reduced > _roll(x, -i)[n:-n]\n",
    "    return np.sum(res)\n",
    "a = np.random.randn(24)\n",
    "num_peaks(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2050cb53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:43.895879Z",
     "start_time": "2023-07-10T01:19:43.893730Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def c3(x, lag = 5):\n",
    "    \"\"\"\n",
    "    Uses c3 statistics to measure non linearity in the time series\n",
    "\n",
    "    This function calculates the value of\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\frac{1}{n-2lag} \\\\sum_{i=1}^{n-2lag} x_{i + 2 \\\\cdot lag} \\\\cdot x_{i + lag} \\\\cdot x_{i}\n",
    "\n",
    "    which is\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\mathbb{E}[L^2(X) \\\\cdot L(X) \\\\cdot X]\n",
    "\n",
    "    where :math:`\\\\mathbb{E}` is the mean and :math:`L` is the lag operator. It was proposed in [1] as a measure of\n",
    "    non linearity in the time series.\n",
    "\n",
    "    .. rubric:: References\n",
    "\n",
    "    |  [1] Schreiber, T. and Schmitz, A. (1997).\n",
    "    |  Discrimination power of measures for nonlinearity in a time series\n",
    "    |  PHYSICAL REVIEW E, VOLUME 55, NUMBER 5\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param lag: the lag that should be used in the calculation of the feature\n",
    "    :type lag: int\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    n = x.size\n",
    "    if 2 * lag >= n:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean((_roll(x, 2 * -lag) * _roll(x, -lag) * x)[0 : (n - 2 * lag)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321874e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:43.902841Z",
     "start_time": "2023-07-10T01:19:43.896625Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3263420713880414"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_quant(x, ql = 0.2, qh = 0.8, isabs = True, f_agg = \"std\"):\n",
    "    \"\"\"\n",
    "    First fixes a corridor given by the quantiles ql and qh of the distribution of x.\n",
    "    Then calculates the average, absolute value of consecutive changes of the series x inside this corridor.\n",
    "\n",
    "    Think about selecting a corridor on the\n",
    "    y-Axis and only calculating the mean of the absolute change of the time series inside this corridor.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param ql: the lower quantile of the corridor\n",
    "    :type ql: float\n",
    "    :param qh: the higher quantile of the corridor\n",
    "    :type qh: float\n",
    "    :param isabs: should the absolute differences be taken?\n",
    "    :type isabs: bool\n",
    "    :param f_agg: the aggregator function that is applied to the differences in the bin\n",
    "    :type f_agg: str, name of a numpy function (e.g. mean, var, std, median)\n",
    "\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if ql >= qh:\n",
    "        return 0\n",
    "\n",
    "    div = np.diff(x)\n",
    "    if isabs:\n",
    "        div = np.abs(div)\n",
    "    # All values that originate from the corridor between the quantiles ql and qh will have the category 0,\n",
    "    # other will be np.NaN\n",
    "    try:\n",
    "        bin_cat = pd.qcut(x, [ql, qh], labels=False)\n",
    "        bin_cat_0 = bin_cat == 0\n",
    "    except ValueError:  # Occurs when ql are qh effectively equal, e.g. x is not long enough or is too categorical\n",
    "        return 0\n",
    "    # We only count changes that start and end inside the corridor\n",
    "    ind = (bin_cat_0 & _roll(bin_cat_0, 1))[1:]\n",
    "\n",
    "    if np.sum(ind) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        ind_inside_corridor = np.where(ind == 1)\n",
    "\n",
    "        aggregator = getattr(np, f_agg)\n",
    "        return aggregator(div[ind_inside_corridor])\n",
    "    \n",
    "a = np.random.randn(24)\n",
    "change_quant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f22d2e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:43.905610Z",
     "start_time": "2023-07-10T01:19:43.903452Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cid_ce(x, normalize = True):\n",
    "    \"\"\"\n",
    "    This function calculator is an estimate for a time series complexity [1] (A more complex time series has more peaks,\n",
    "    valleys etc.). It calculates the value of\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\sqrt{ \\\\sum_{i=1}^{n-1} ( x_{i} - x_{i-1})^2 }\n",
    "\n",
    "    .. rubric:: References\n",
    "\n",
    "    |  [1] Batista, Gustavo EAPA, et al (2014).\n",
    "    |  CID: an efficient complexity-invariant distance for time series.\n",
    "    |  Data Mining and Knowledge Discovery 28.3 (2014): 634-669.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param normalize: should the time series be z-transformed?\n",
    "    :type normalize: bool\n",
    "\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "        x = np.asarray(x)\n",
    "    if normalize:\n",
    "        s = np.std(x)\n",
    "        if s != 0:\n",
    "            x = (x - np.mean(x)) / s\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    x = np.diff(x)\n",
    "    return np.sqrt(np.dot(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2828c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:44.463157Z",
     "start_time": "2023-07-10T01:19:43.906209Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1414772041616543"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import cwt, ricker\n",
    "\n",
    "def cwt_coeff(x, widths=tuple([2,2,2]), coeff=2, w=2):\n",
    "    \"\"\"\n",
    "    Calculates a Continuous wavelet transform for the Ricker wavelet, also known as the \"Mexican hat wavelet\" which is\n",
    "    defined by\n",
    "\n",
    "    .. math::\n",
    "        \\\\frac{2}{\\\\sqrt{3a} \\\\pi^{\\\\frac{1}{4}}} (1 - \\\\frac{x^2}{a^2}) exp(-\\\\frac{x^2}{2a^2})\n",
    "\n",
    "    where :math:`a` is the width parameter of the wavelet function.\n",
    "\n",
    "    This feature calculator takes three different parameter: widths, coeff and w. The feature calculator takes all the\n",
    "    different widths arrays and then calculates the cwt one time for each different width array. Then the values for the\n",
    "    different coefficient for coeff and width w are returned. (For each dic in param one feature is returned)\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param param: contains dictionaries {\"widths\":x, \"coeff\": y, \"w\": z} with x array of int and y,z int\n",
    "    :type param: list\n",
    "    :return: the different feature values\n",
    "    :return type: pandas.Series\n",
    "    \"\"\"\n",
    "    calculated = cwt(x, ricker, widths)\n",
    "    i = widths.index(w)\n",
    "    if calculated.shape[1] <= coeff:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return calculated[i, coeff]\n",
    "\n",
    "a = np.random.randn(24)\n",
    "cwt_coeff(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "791a6c94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:44.466826Z",
     "start_time": "2023-07-10T01:19:44.464002Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030420353073445032"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ener_ratio_chunks(x, num_segments= 10, segment_focus = 9):\n",
    "    \"\"\"\n",
    "    Calculates the sum of squares of chunk i out of N chunks expressed as a ratio with the sum of squares over the whole\n",
    "    series.\n",
    "\n",
    "    Takes as input parameters the number num_segments of segments to divide the series into and segment_focus\n",
    "    which is the segment number (starting at zero) to return a feature on.\n",
    "\n",
    "    If the length of the time series is not a multiple of the number of segments, the remaining data points are\n",
    "    distributed on the bins starting from the first. For example, if your time series consists of 8 entries, the\n",
    "    first two bins will contain 3 and the last two values, e.g. `[ 0.,  1.,  2.], [ 3.,  4.,  5.]` and `[ 6.,  7.]`.\n",
    "\n",
    "    Note that the answer for `num_segments = 1` is a trivial \"1\" but we handle this scenario\n",
    "    in case somebody calls it. Sum of the ratios should be 1.0.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param param: contains dictionaries {\"num_segments\": N, \"segment_focus\": i} with N, i both ints\n",
    "    :return: the feature values\n",
    "    :return type: list of tuples (index, data)\n",
    "    \"\"\"\n",
    "\n",
    "    full_series_energy = np.sum(x**2)\n",
    "    \n",
    "    assert segment_focus < num_segments # segment_focus 的意思是你关心哪一个子块\n",
    "    assert num_segments > 0\n",
    "\n",
    "    if full_series_energy == 0:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return np.sum(np.array_split(x, num_segments)[segment_focus] ** 2.0) / full_series_energy\n",
    "a = np.random.randn(24)\n",
    "ener_ratio_chunks(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f72a156e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:44.470383Z",
     "start_time": "2023-07-10T01:19:44.467489Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.195022805944566"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fft_coeff(x, coeff=10, attr= \"abs\"):\n",
    "    \"\"\"\n",
    "    Calculates the fourier coefficients of the one-dimensional discrete Fourier Transform for real input by fast\n",
    "    fourier transformation algorithm\n",
    "\n",
    "    .. math::\n",
    "        A_k =  \\\\sum_{m=0}^{n-1} a_m \\\\exp \\\\left \\\\{ -2 \\\\pi i \\\\frac{m k}{n} \\\\right \\\\}, \\\\qquad k = 0,\n",
    "        \\\\ldots , n-1.\n",
    "\n",
    "    The resulting coefficients will be complex, this feature calculator can return the real part (attr==\"real\"),\n",
    "    the imaginary part (attr==\"imag), the absolute value (attr=\"\"abs) and the angle in degrees (attr==\"angle).\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param param: contains dictionaries {\"coeff\": x, \"attr\": s} with x int and x >= 0, s str and in [\"real\", \"imag\",\n",
    "        \"abs\", \"angle\"]\n",
    "    :type param: list\n",
    "    :return: the different feature values\n",
    "    :return type: pandas.Series\n",
    "    \"\"\"\n",
    "\n",
    "    assert coeff >= 0, \"Coefficients must be positive or zero.\"\n",
    "    assert {attr} <= {\n",
    "        \"imag\",\n",
    "        \"real\",\n",
    "        \"abs\",\n",
    "        \"angle\",\n",
    "    }, 'Attribute must be \"real\", \"imag\", \"angle\" or \"abs\"'\n",
    "\n",
    "    fft = np.fft.rfft(x)\n",
    "\n",
    "    res = getattr(np, attr)(fft[coeff]) if coeff < len(fft) else np.NaN\n",
    "    \n",
    "    return res\n",
    "a = np.random.randn(24)\n",
    "fft_coeff(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "798e1f63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:44.475140Z",
     "start_time": "2023-07-10T01:19:44.471183Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2636256721237276"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import welch\n",
    "def fourier_entropy(x, bins = 5):\n",
    "    \"\"\"\n",
    "    Calculate the binned entropy of the power spectral density of the time series\n",
    "    (using the welch method).\n",
    "\n",
    "    Ref: https://hackaday.io/project/707-complexity-of-a-time-series/details\n",
    "    Ref: https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.signal.welch.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def binned_entropy(x, max_bins):\n",
    "        \"\"\"\n",
    "        First bins the values of x into max_bins equidistant bins.\n",
    "        Then calculates the value of\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            - \\\\sum_{k=0}^{min(max\\\\_bins, len(x))} p_k log(p_k) \\\\cdot \\\\mathbf{1}_{(p_k > 0)}\n",
    "\n",
    "        where :math:`p_k` is the percentage of samples in bin :math:`k`.\n",
    "\n",
    "        :param x: the time series to calculate the feature of\n",
    "        :type x: numpy.ndarray\n",
    "        :param max_bins: the maximal number of bins\n",
    "        :type max_bins: int\n",
    "        :return: the value of this feature\n",
    "        :return type: float\n",
    "        \"\"\"\n",
    "        if not isinstance(x, (np.ndarray, pd.Series)):\n",
    "            x = np.asarray(x)\n",
    "\n",
    "        # nan makes no sense here\n",
    "        if np.isnan(x).any():\n",
    "            return np.nan\n",
    "\n",
    "        hist, bin_edges = np.histogram(x, bins=max_bins)\n",
    "        probs = hist / x.size\n",
    "        probs[probs == 0] = 1.0\n",
    "        return -np.sum(probs * np.log(probs))\n",
    "    \n",
    "    _, pxx = welch(x, nperseg=min((len(x), 256)))\n",
    "    return binned_entropy(pxx / np.max(pxx), bins)\n",
    "a = np.random.randn(24)\n",
    "fourier_entropy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "02c5543e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T05:07:13.314251Z",
     "start_time": "2023-07-10T05:07:13.303245Z"
    },
    "code_folding": [
     0,
     25
    ]
   },
   "outputs": [],
   "source": [
    "def _into_subchunks(x, subchunk_length, every_n=1):\n",
    "    \"\"\"\n",
    "    Split the time series x into subwindows of length \"subchunk_length\", starting every \"every_n\".\n",
    "\n",
    "    For example, the input data if [0, 1, 2, 3, 4, 5, 6] will be turned into a matrix\n",
    "\n",
    "        0  2  4\n",
    "        1  3  5\n",
    "        2  4  6\n",
    "\n",
    "    with the settings subchunk_length = 3 and every_n = 2\n",
    "    \"\"\"\n",
    "    len_x = len(x)\n",
    "\n",
    "    assert subchunk_length > 1\n",
    "    assert every_n > 0\n",
    "\n",
    "    # how often can we shift a window of size subchunk_length over the input?\n",
    "    num_shifts = (len_x - subchunk_length) // every_n + 1\n",
    "    shift_starts = every_n * np.arange(num_shifts)\n",
    "    indices = np.arange(subchunk_length)\n",
    "\n",
    "    indexer = np.expand_dims(indices, axis=0) + np.expand_dims(shift_starts, axis=1)\n",
    "    return np.asarray(x)[indexer]\n",
    "\n",
    "def permu_entropy(x, tau = 5, dimension = 2): # 这里将tau 设置为5就注定无法仅根据5天的数据计算\n",
    "    \"\"\"\n",
    "    Calculate the permutation entropy.\n",
    "\n",
    "    Three steps are needed for this:\n",
    "\n",
    "    1. chunk the data into sub-windows of length D starting every tau.\n",
    "       Following the example from the reference, a vector\n",
    "\n",
    "        x = [4, 7, 9, 10, 6, 11, 3\n",
    "\n",
    "       with D = 3 and tau = 1 is turned into\n",
    "\n",
    "           [[ 4,  7,  9],\n",
    "            [ 7,  9, 10],\n",
    "            [ 9, 10,  6],\n",
    "            [10,  6, 11],\n",
    "            [ 6, 11,  3]]\n",
    "\n",
    "    2. replace each D-window by the permutation, that\n",
    "       captures the ordinal ranking of the data.\n",
    "       That gives\n",
    "\n",
    "           [[0, 1, 2],\n",
    "            [0, 1, 2],\n",
    "            [1, 2, 0],\n",
    "            [1, 0, 2],\n",
    "            [1, 2, 0]]\n",
    "\n",
    "    3. Now we just need to count the frequencies of every permutation\n",
    "       and return their entropy (we use log_e and not log_2).\n",
    "\n",
    "    Ref: https://www.aptech.com/blog/permutation-entropy/\n",
    "         Bandt, Christoph and Bernd Pompe.\n",
    "         “Permutation entropy: a natural complexity measure for time series.”\n",
    "         Physical review letters 88 17 (2002): 174102 .\n",
    "    \"\"\"\n",
    "\n",
    "    X = _into_subchunks(x, dimension, tau)\n",
    "    if len(X) == 0:\n",
    "        return np.nan\n",
    "    # Now that is clearly black, magic, but see here:\n",
    "    # https://stackoverflow.com/questions/54459554/numpy-find-index-in-sorted-array-in-an-efficient-way\n",
    "    permutations = np.argsort(np.argsort(X))\n",
    "    # Count the number of occurences\n",
    "    _, counts = np.unique(permutations, axis=0, return_counts=True)\n",
    "    # turn them into frequencies\n",
    "    probs = counts / len(permutations)\n",
    "    # and return their entropy\n",
    "    return -np.sum(probs * np.log(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "373b9734",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T05:24:48.027392Z",
     "start_time": "2023-07-10T05:24:48.005060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.015821905303942785"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathos.multiprocessing import ThreadPool as Pool #多线程\n",
    "def approx_entropy (s :list|np.ndarray, r:float= .2 , m :int =2): # 近似熵\n",
    "    s = np.squeeze(np.asarray(s))\n",
    "    th = r * np.std(s) #容限阈值\n",
    "    def phi (m):\n",
    "        n = len(s)\n",
    "        x = s[ np.arange(n-m+1).reshape(-1,1) + np.arange(m) ]\n",
    "        ci = lambda xi: (( np.abs(x-xi).max(1) <=th).sum()) / (n-m+1) # 构建一个匿名函数\n",
    "        c = Pool().map (ci, x) #所传递的参数格式: 函数名,函数参数\n",
    "        return np.sum(np.log(c)) /(n-m+1)\n",
    "    x = Pool().map(phi, [m, m+1])\n",
    "    return x[1] - x[0]\n",
    "a = np.random.randn(24)\n",
    "approx_entropy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3c988f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T05:57:01.747124Z",
     "start_time": "2023-07-10T05:57:01.722458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3862943611198908"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_entropy(Datalist, r=.2, m=2): # 样本熵\n",
    "    Datalist = np.asarray(Datalist)\n",
    "    list_len = len(Datalist)  #总长度\n",
    "    th = r * np.std(Datalist) #容限阈值\n",
    "    def Phi(k):\n",
    "        list_split = [Datalist[i:i+k] for i in range(0,list_len-k+(k-m))] #将其拆分成多个子列表\n",
    "        #这里需要注意，2维和3维分解向量时的方式是不一样的！！！\n",
    "        Bm = 0.0\n",
    "        for i in range(0, len(list_split)): #遍历每个子向量\n",
    "            Bm += ((np.abs(list_split[i] - list_split).max(1) <= th).sum()-1) / (len(list_split)-1) #注意分子和分母都要减1\n",
    "        return Bm\n",
    "    ## 多线程\n",
    "    x = Pool().map(Phi, [m,m+1])\n",
    "    return - np.log(x[1] / x[0]) \n",
    "#     H = - math.log(Phi(m+1) / Phi(m))\n",
    "    \n",
    "a = np.random.randn(60)\n",
    "sample_entropy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f41833eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T05:57:18.565248Z",
     "start_time": "2023-07-10T05:57:18.541025Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9069144059598258"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fuzzy_entropy(s, r = 0.2, m = 2, n = 2): # 模糊熵\n",
    "    '''s:需要计算熵的向量; r:阈值容限(标准差的系数); m:向量维数; n:模糊函数的指数\n",
    "    '''\n",
    "    s = np.asarray(s)\n",
    "    N = len(s)  #总长度\n",
    "    th = r * np.std(s) #容限阈值\n",
    "    def Phi(k):\n",
    "        list_split = [s[i:i+k] for i in range(0,N-k+(k-m))] #将其拆分成多个子列表\n",
    "        #这里需要注意，2维和3维分解向量时的方式是不一样的！！！\n",
    "        B = np.zeros(len(list_split))\n",
    "        for i in range(0, len(list_split)): #遍历每个子向量\n",
    "            di = np.abs(list_split[i] - np.mean(list_split[i]) - list_split + np.mean(list_split,1).reshape(-1,1)).max(1)\n",
    "            Di = np.exp(- np.power(di,n) / th)\n",
    "            B[i] = (np.sum(Di) - 1) / (len(list_split)-1) #这里减1是因为要除去其本身，即exp(0)\n",
    "        return np.sum(B) / len(list_split)\n",
    "    \n",
    "    x = Pool().map(Phi, [m, m+1])\n",
    "    return - np.log(x[1]/ x[0])\n",
    "a = np.random.randn(24)\n",
    "fuzzy_entropy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ca541156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T23:05:25.539087Z",
     "start_time": "2023-07-10T05:58:49.261649Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation of approx_entropy Freq60 has completed!\n",
      "Calculation of sample_entropy Freq60 has completed!\n",
      "Calculation of fuzzy_entropy Freq60 has completed!\n",
      "Calculation of permu_entropy Freq60 has completed!\n",
      "Calculation of approx_entropy Freq126 has completed!\n",
      "Calculation of sample_entropy Freq126 has completed!\n",
      "Calculation of fuzzy_entropy Freq126 has completed!\n",
      "Calculation of permu_entropy Freq126 has completed!\n",
      "Calculation of approx_entropy Freq252 has completed!\n",
      "Calculation of sample_entropy Freq252 has completed!\n",
      "Calculation of fuzzy_entropy Freq252 has completed!\n",
      "Calculation of permu_entropy Freq252 has completed!\n",
      "Total time cost = 1026.60 mins.\n"
     ]
    }
   ],
   "source": [
    "# 函数测试诊断：多窗口\n",
    "is_intersect = False\n",
    "time1 = time.time()\n",
    "for train_window in [60, 126, 252]:\n",
    "    \n",
    "    for func_name in ['approx_entropy','sample_entropy','fuzzy_entropy','permu_entropy']:\n",
    "        \n",
    "        note = f'Day{train_window}'+func_name\n",
    "        get_Xt = eval(func_name)\n",
    "        \n",
    "        main(get_Xt=get_Xt,\n",
    "             start_day=20210101,\n",
    "             end_day=20221231,\n",
    "             skip_first_day=True,\n",
    "             step=5,\n",
    "             note=note,\n",
    "             is_display=False,\n",
    "             )\n",
    "\n",
    "        print(f'Calculation of {func_name} Freq{train_window} has completed!')\n",
    "time2 = time.time()\n",
    "print(f'Total time cost = {(time2 - time1)/60 :.2f} mins.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24abd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:44.770308Z",
     "start_time": "2023-07-10T01:19:44.770301Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "def spkt_welch_dens(x, coeff = 3):\n",
    "    \"\"\"\n",
    "    This feature calculator estimates the cross power spectral density of the time series x at different frequencies.\n",
    "    To do so, the time series is first shifted from the time domain to the frequency domain.\n",
    "\n",
    "    The feature calculators returns the power spectrum of the different frequencies.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param param: contains dictionaries {\"coeff\": x} with x int\n",
    "    :type param: list\n",
    "    :return: the different feature values\n",
    "    :return type: pandas.Series\n",
    "    \"\"\"\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy-signal-welch\n",
    "\n",
    "    freq, pxx = welch(x, nperseg=min(len(x), 256))\n",
    "    display(pxx)\n",
    "\n",
    "    if len(pxx) <= np.max(coeff):  \n",
    "        # There are fewer data points in the time series than requested coefficients\n",
    "        print('if')\n",
    "        # filter coefficients that are not contained in pxx\n",
    "        reduced_coeff = [coeff] if len(pxx) > coeff else []\n",
    "        not_calculated_coefficients = [coeff] if coeff not in reduced_coeff else []\n",
    "\n",
    "        # Fill up the rest of the requested coefficients with np.NaNs\n",
    "        return np.array(list(pxx[reduced_coeff]) + [np.NaN] * len(not_calculated_coefficients))\n",
    "    else:\n",
    "        print('else')\n",
    "        return np.array(pxx[coeff])\n",
    "a = np.random.randn(5)\n",
    "display(a)\n",
    "spkt_welch_dens(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6c83a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:44.770786Z",
     "start_time": "2023-07-10T01:19:44.770781Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ti_rev_asym_stat(x, lag = 2):\n",
    "    \"\"\"\n",
    "    Returns the time reversal asymmetry statistic.\n",
    "\n",
    "    This function calculates the value of\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\frac{1}{n-2lag} \\\\sum_{i=1}^{n-2lag} x_{i + 2 \\\\cdot lag}^2 \\\\cdot x_{i + lag} - x_{i + lag} \\\\cdot  x_{i}^2\n",
    "\n",
    "    which is\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\\\mathbb{E}[L^2(X)^2 \\\\cdot L(X) - L(X) \\\\cdot X^2]\n",
    "\n",
    "    where :math:`\\\\mathbb{E}` is the mean and :math:`L` is the lag operator. It was proposed in [1] as a\n",
    "    promising feature to extract from time series.\n",
    "\n",
    "    .. rubric:: References\n",
    "\n",
    "    |  [1] Fulcher, B.D., Jones, N.S. (2014).\n",
    "    |  Highly comparative feature-based time-series classification.\n",
    "    |  Knowledge and Data Engineering, IEEE Transactions on 26, 3026–3037.\n",
    "\n",
    "    :param x: the time series to calculate the feature of\n",
    "    :type x: numpy.ndarray\n",
    "    :param lag: the lag that should be used in the calculation of the feature\n",
    "    :type lag: int\n",
    "    :return: the value of this feature\n",
    "    :return type: float\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    x = np.asarray(x)\n",
    "    if 2 * lag >= n:\n",
    "        return 0\n",
    "    else:\n",
    "        one_lag = _roll(x, -lag)\n",
    "        two_lag = _roll(x, 2 * -lag)\n",
    "        return np.mean(\n",
    "            (two_lag * two_lag * one_lag - one_lag * x * x)[0 : (n - 2 * lag)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b35fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T07:38:04.378379Z",
     "start_time": "2023-07-07T07:38:04.347654Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193981d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:19:44.771664Z",
     "start_time": "2023-07-10T01:19:44.771658Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 函数测试诊断：单窗口\n",
    "train_window = 60\n",
    "time1 = time.time()\n",
    "is_intersect = False\n",
    "\n",
    "get_Xt = num_peaks\n",
    "note = None\n",
    "\n",
    "main(get_Xt=get_Xt,\n",
    "     start_day=20210101,\n",
    "     end_day=20221231,\n",
    "     skip_first_day=True,\n",
    "     step=5,\n",
    "     note=note,\n",
    "     is_display=True,\n",
    "     )\n",
    "\n",
    "print(f'Calculation has completed!')\n",
    "time2 = time.time()\n",
    "print(f'Total time cost = {(time2 - time1)/60 :.2f} mins.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
